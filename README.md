# Capstone

## Driver Ranking Prediction
This application aims to predict the ranking of drivers in their respective leagues based on various attributes. The data used for training and evaluation is loaded from five different sources, each consisting of driver names and corresponding attributes.

## Data Sources
The data is collected from the following sources:

* DriverDbGb4: WRC drivers' attributes
* KaggleFormula1 (1950-2020): Formula 1 drivers' attributes
* WikipediaFormulaE: Formula E drivers' attributes
* WRC2022: World Rally Championship drivers' attributes
* KaggleNascarAdvancedStats2022: NASCAR drivers' attributes

Please note that the data generated for this application was created with the assistance of ChatGPT and does not reflect the real performance of drivers. Consequently, the training of models may encounter issues due to the unreliable nature of the data. The limited number of positive cases, where drivers are actually in the top three, further contributes to the models' lower reliability. Increasing the size of the test sample might lead to better models and more accurate predictions.

## Code Overview
The provided code performs the following steps:

1. Imports necessary libraries and modules. 
2. Reads the data from the five different sources into separate DataFrames.
3. Adds columns to the DataFrames representing the International Car Racing Sports (ICRS) organization and the local and international Car Racing Federations (CRF) for each source.

4. Merges the individual DataFrames into a single DataFrame called "merged."

5. Iterates through the merged dataset to create a binary classification target variable "IsTopThree," indicating whether a driver finishes in the top three (1) or not (0) at the end of the season.

6. Splits the dataset into features (X) and the target variable (y).

7. Defines and trains several classic machine learning models using the training data. 
8. Evaluates the performance of each model by calculating accuracy, precision, recall, F1-score, and generating a classification report and confusion matrix.

9. Plots the receiver operating characteristic (ROC) curve and calculates the area under the curve (AUC) for each model.

10. Reduces the number of features using the ExtraTreesClassifier and SelectFromModel.

11. Repeats the training, evaluation, and plotting steps with the pruned feature set.

12. Reshapes the input data for training a Convolutional Neural Network (CNN) with LSTM layers.

13. Defines, compiles, and trains the CNN model.

14. Evaluates the trained CNN model and calculates accuracy.

15. Predicts class probabilities and extracts probabilities for the positive class.

16. Calculates the false positive rate (FPR), true positive rate (TPR), and threshold values.

17. Calculates the area under the ROC curve (AUC) and the confusion matrix.
18. Plots the ROC curve and the confusion matrix for the CNN model.
## Results
The results of the classic machine learning models, including accuracy, precision, recall, F1-score, and confusion matrix, are displayed for each model. Additionally, ROC curves and AUC scores are plotted to evaluate the models' performance.

After feature reduction using the ExtraTreesClassifier and SelectFromModel, the classic machine learning models are trained and evaluated again with the pruned feature set.

Finally, a CNN model with LSTM layers is trained and evaluated, and the ROC curve and confusion matrix are plotted to assess its performance.

Please refer to the figures and evaluation metrics generated by the code for detailed results and analysis.
Overall, the Decision Tree and Random Forest models demonstrate the best performance among the classic models, achieving high accuracy and balanced scores for precision, recall, and F1-score in both classes. The k-Nearest Neighbors and Naive Bayes models also show reasonably good performance, although they struggle with predicting class 1. The Logistic Regression and Support Vector Classifier models perform poorly in predicting class 1, with zero scores for precision, recall, and F1-score.

It can be mentioned that the quality of the classic models slightly improved after pruning the features.

Note: The code may take some time to execute, depending on the size of the dataset and the complexity of the models.




